{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from ultralytics import YOLO\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger le modèle YOLOv8\n",
    "yolo = YOLO(\"./models/yolov8n.pt\")\n",
    "\n",
    "# Charger la cascade de Haar pour la détection de visage\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Charger le modèle de reconnaissance de célébrités\n",
    "modelCNN = load_model(\"./models/celebrity_recognition.h5\")\n",
    "\n",
    "# Charger l'encodeur d'étiquettes\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.classes_ = np.load('./models/label_encoder_classes.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capture vidéo à partir d'un fichier\n",
    "cap = cv2.VideoCapture('./input1.mp4')\n",
    "\n",
    "# Obtention de la fréquence d'images par seconde (FPS) et des dimensions du cadre vidéo\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "# Configuration de l'encodeur vidéo pour la sortie\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "video_out = cv2.VideoWriter('output.mp4', fourcc, fps, (width, height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour prédire la classe d'une région d'intérêt (ROI) du visage\n",
    "def predict_face_roi(face_roi, model, label_encoder):\n",
    "    face_roi = cv2.resize(face_roi, (64, 64))  \n",
    "    face_roi = np.array(face_roi) / 255.0\n",
    "    face_roi = np.expand_dims(face_roi, axis=0)  \n",
    "\n",
    "    predictions = modelCNN.predict(face_roi)\n",
    "    predicted_class_index = np.argmax(predictions)\n",
    "    predicted_class_accuracy = predictions[0, predicted_class_index]\n",
    "\n",
    "    if predicted_class_accuracy < 0.96:\n",
    "        return \"inconnu\", predicted_class_accuracy\n",
    "\n",
    "    predicted_class_name = label_encoder.classes_[predicted_class_index]\n",
    "    return predicted_class_name, predicted_class_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 187.3ms\n",
      "Speed: 0.0ms preprocess, 187.3ms inference, 12.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "1/1 [==============================] - 0s 267ms/step\n",
      "\n",
      "0: 384x640 1 person, 195.4ms\n",
      "Speed: 0.0ms preprocess, 195.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "\n",
      "0: 384x640 1 person, 170.8ms\n",
      "Speed: 0.0ms preprocess, 170.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "\n",
      "0: 384x640 1 person, 154.2ms\n",
      "Speed: 19.1ms preprocess, 154.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "\n",
      "0: 384x640 1 person, 160.9ms\n",
      "Speed: 4.1ms preprocess, 160.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "\n",
      "0: 384x640 1 person, 209.7ms\n",
      "Speed: 15.6ms preprocess, 209.7ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "\n",
      "0: 384x640 1 person, 167.5ms\n",
      "Speed: 3.0ms preprocess, 167.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "\n",
      "0: 384x640 1 person, 175.5ms\n",
      "Speed: 3.0ms preprocess, 175.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "\n",
      "0: 384x640 1 person, 150.2ms\n",
      "Speed: 15.6ms preprocess, 150.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "\n",
      "0: 384x640 1 person, 150.6ms\n",
      "Speed: 0.0ms preprocess, 150.6ms inference, 14.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "\n",
      "0: 384x640 1 person, 196.4ms\n",
      "Speed: 0.0ms preprocess, 196.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "\n",
      "0: 384x640 1 person, 162.4ms\n",
      "Speed: 0.0ms preprocess, 162.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "\n",
      "0: 384x640 1 person, 162.5ms\n",
      "Speed: 1.8ms preprocess, 162.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "\n",
      "0: 384x640 1 person, 160.0ms\n",
      "Speed: 4.2ms preprocess, 160.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "\n",
      "0: 384x640 1 person, 160.4ms\n",
      "Speed: 2.1ms preprocess, 160.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "\n",
      "0: 384x640 1 person, 172.2ms\n",
      "Speed: 0.0ms preprocess, 172.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "\n",
      "0: 384x640 1 person, 161.1ms\n",
      "Speed: 4.5ms preprocess, 161.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "\n",
      "0: 384x640 1 person, 169.7ms\n",
      "Speed: 0.0ms preprocess, 169.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "\n",
      "0: 384x640 1 person, 141.5ms\n",
      "Speed: 1.8ms preprocess, 141.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "\n",
      "0: 384x640 1 person, 181.7ms\n",
      "Speed: 0.0ms preprocess, 181.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "\n",
      "0: 384x640 1 person, 175.7ms\n",
      "Speed: 15.6ms preprocess, 175.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "\n",
      "0: 384x640 1 person, 164.5ms\n",
      "Speed: 2.0ms preprocess, 164.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "\n",
      "0: 384x640 1 person, 156.6ms\n",
      "Speed: 3.9ms preprocess, 156.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "\n",
      "0: 384x640 1 person, 153.0ms\n",
      "Speed: 18.9ms preprocess, 153.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "\n",
      "0: 384x640 1 person, 156.8ms\n",
      "Speed: 15.6ms preprocess, 156.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "\n",
      "0: 384x640 1 person, 162.1ms\n",
      "Speed: 0.0ms preprocess, 162.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "\n",
      "0: 384x640 1 person, 138.4ms\n",
      "Speed: 0.3ms preprocess, 138.4ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "\n",
      "0: 384x640 1 person, 161.0ms\n",
      "Speed: 1.3ms preprocess, 161.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "\n",
      "0: 384x640 1 person, 146.8ms\n",
      "Speed: 3.1ms preprocess, 146.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "\n",
      "0: 384x640 1 person, 141.1ms\n",
      "Speed: 2.3ms preprocess, 141.1ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "\n",
      "0: 384x640 1 person, 171.1ms\n",
      "Speed: 0.0ms preprocess, 171.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "\n",
      "0: 384x640 1 person, 130.1ms\n",
      "Speed: 2.3ms preprocess, 130.1ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "\n",
      "0: 384x640 1 person, 145.2ms\n",
      "Speed: 3.0ms preprocess, 145.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "\n",
      "0: 384x640 1 person, 164.8ms\n",
      "Speed: 3.0ms preprocess, 164.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "\n",
      "0: 384x640 1 person, 149.3ms\n",
      "Speed: 16.5ms preprocess, 149.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "\n",
      "0: 384x640 1 person, 175.5ms\n",
      "Speed: 3.0ms preprocess, 175.5ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "\n",
      "0: 384x640 1 person, 162.6ms\n",
      "Speed: 5.0ms preprocess, 162.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "\n",
      "0: 384x640 1 person, 161.1ms\n",
      "Speed: 3.0ms preprocess, 161.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "\n",
      "0: 384x640 1 person, 147.4ms\n",
      "Speed: 0.0ms preprocess, 147.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "\n",
      "0: 384x640 1 person, 168.1ms\n",
      "Speed: 0.0ms preprocess, 168.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "\n",
      "0: 384x640 1 person, 150.3ms\n",
      "Speed: 0.0ms preprocess, 150.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "\n",
      "0: 384x640 1 person, 174.5ms\n",
      "Speed: 15.6ms preprocess, 174.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "\n",
      "0: 384x640 1 person, 169.9ms\n",
      "Speed: 0.0ms preprocess, 169.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "\n",
      "0: 384x640 1 person, 170.9ms\n",
      "Speed: 0.0ms preprocess, 170.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "\n",
      "0: 384x640 1 person, 183.2ms\n",
      "Speed: 0.0ms preprocess, 183.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "\n",
      "0: 384x640 1 person, 138.7ms\n",
      "Speed: 0.0ms preprocess, 138.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "\n",
      "0: 384x640 1 person, 148.5ms\n",
      "Speed: 2.8ms preprocess, 148.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "\n",
      "0: 384x640 1 person, 184.0ms\n",
      "Speed: 3.0ms preprocess, 184.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "\n",
      "0: 384x640 1 person, 177.8ms\n",
      "Speed: 4.0ms preprocess, 177.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "\n",
      "0: 384x640 1 person, 198.7ms\n",
      "Speed: 3.0ms preprocess, 198.7ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "\n",
      "0: 384x640 1 person, 178.1ms\n",
      "Speed: 6.3ms preprocess, 178.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "\n",
      "0: 384x640 1 person, 191.7ms\n",
      "Speed: 2.0ms preprocess, 191.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "\n",
      "0: 384x640 1 person, 163.6ms\n",
      "Speed: 6.0ms preprocess, 163.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "\n",
      "0: 384x640 1 person, 223.1ms\n",
      "Speed: 5.0ms preprocess, 223.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "\n",
      "0: 384x640 1 person, 176.9ms\n",
      "Speed: 0.0ms preprocess, 176.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "\n",
      "0: 384x640 1 person, 183.8ms\n",
      "Speed: 4.0ms preprocess, 183.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "\n",
      "0: 384x640 1 person, 177.3ms\n",
      "Speed: 6.0ms preprocess, 177.3ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "\n",
      "0: 384x640 1 person, 169.5ms\n",
      "Speed: 4.0ms preprocess, 169.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 165.1ms\n",
      "Speed: 15.6ms preprocess, 165.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "\n",
      "0: 384x640 1 person, 152.4ms\n",
      "Speed: 3.0ms preprocess, 152.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "\n",
      "0: 384x640 1 person, 211.2ms\n",
      "Speed: 15.6ms preprocess, 211.2ms inference, 16.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "\n",
      "0: 384x640 1 person, 137.7ms\n",
      "Speed: 0.0ms preprocess, 137.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "\n",
      "0: 384x640 1 person, 171.9ms\n",
      "Speed: 0.0ms preprocess, 171.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "\n",
      "0: 384x640 1 person, 156.2ms\n",
      "Speed: 0.0ms preprocess, 156.2ms inference, 15.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "\n",
      "0: 384x640 1 person, 165.6ms\n",
      "Speed: 0.0ms preprocess, 165.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "\n",
      "0: 384x640 1 person, 171.8ms\n",
      "Speed: 0.0ms preprocess, 171.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "\n",
      "0: 384x640 1 person, 156.2ms\n",
      "Speed: 0.0ms preprocess, 156.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "\n",
      "0: 384x640 1 person, 159.6ms\n",
      "Speed: 3.0ms preprocess, 159.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "\n",
      "0: 384x640 1 person, 171.5ms\n",
      "Speed: 5.0ms preprocess, 171.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "\n",
      "0: 384x640 1 person, 134.5ms\n",
      "Speed: 15.6ms preprocess, 134.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "\n",
      "0: 384x640 1 person, 171.8ms\n",
      "Speed: 0.0ms preprocess, 171.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "\n",
      "0: 384x640 1 person, 164.7ms\n",
      "Speed: 0.0ms preprocess, 164.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "\n",
      "0: 384x640 1 person, 144.5ms\n",
      "Speed: 0.0ms preprocess, 144.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "\n",
      "0: 384x640 1 person, 156.2ms\n",
      "Speed: 0.0ms preprocess, 156.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "\n",
      "0: 384x640 1 person, 171.8ms\n",
      "Speed: 0.0ms preprocess, 171.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "\n",
      "0: 384x640 1 person, 171.8ms\n",
      "Speed: 0.0ms preprocess, 171.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "\n",
      "0: 384x640 1 person, 163.0ms\n",
      "Speed: 0.0ms preprocess, 163.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "\n",
      "0: 384x640 1 person, 135.1ms\n",
      "Speed: 15.1ms preprocess, 135.1ms inference, 14.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "\n",
      "0: 384x640 1 person, 163.4ms\n",
      "Speed: 0.0ms preprocess, 163.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "\n",
      "0: 384x640 1 person, 181.3ms\n",
      "Speed: 0.0ms preprocess, 181.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "\n",
      "0: 384x640 1 person, 170.7ms\n",
      "Speed: 0.0ms preprocess, 170.7ms inference, 14.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "\n",
      "0: 384x640 1 person, 160.6ms\n",
      "Speed: 0.0ms preprocess, 160.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "\n",
      "0: 384x640 1 person, 237.6ms\n",
      "Speed: 4.6ms preprocess, 237.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "\n",
      "0: 384x640 1 person, 165.6ms\n",
      "Speed: 4.0ms preprocess, 165.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "\n",
      "0: 384x640 1 person, 147.0ms\n",
      "Speed: 4.0ms preprocess, 147.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "# Traiter chaque image (frame)\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Effectuer la détection d'objets\n",
    "    results = yolo(frame, conf=0.6)\n",
    "\n",
    "    # Traiter chaque personne détectée\n",
    "    for result in results:\n",
    "        boxes = result.boxes\n",
    "\n",
    "        for box in boxes:\n",
    "            cls = int(box.cls[0])\n",
    "\n",
    "            if cls == 0:  # personne\n",
    "                # boîte englobante\n",
    "                x1, y1, x2, y2 = box.xyxy[0]\n",
    "                x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)  # convertir en valeurs entières\n",
    "\n",
    "                # Dessiner une boîte englobante pour la personne\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 3)\n",
    "                \n",
    "                # Extraire la région d'intérêt (ROI)\n",
    "                roi = frame[y1:y2, x1:x2]\n",
    "\n",
    "                # Effectuer la détection de visage sur la ROI\n",
    "                faces = face_cascade.detectMultiScale(roi, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "                # Sélectionner le meilleur visage en fonction de la surface\n",
    "                selected_face = None\n",
    "                max_area = 0\n",
    "\n",
    "                for (fx, fy, fw, fh) in faces:\n",
    "                    face_area = fw * fh\n",
    "                    if face_area > max_area:\n",
    "                        max_area = face_area\n",
    "                        selected_face = (fx, fy, fw, fh)\n",
    "\n",
    "                # Dessiner une boîte englobante pour le meilleur visage\n",
    "                if selected_face is not None:\n",
    "                    (fx, fy, fw, fh) = selected_face\n",
    "                    cv2.rectangle(frame, (x1 + fx, y1 + fy), (x1 + fx + fw, y1 + fy + fh), (255, 0, 0), 2)\n",
    "\n",
    "                    # Extraction de la région d'intérêt du visage\n",
    "                    face_roi = cv2.resize(frame[y1 + selected_face[1]:y1 + selected_face[1] + selected_face[3],\n",
    "                                        x1 + selected_face[0]:x1 + selected_face[0] + selected_face[2]], (256, 256))\n",
    "                    face_roi = cv2.cvtColor(face_roi, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "                    # Prédiction de la célébrité dans la région d'intérêt du visage\n",
    "                    result, confidence = predict_face_roi(frame[y1 + selected_face[1]:y1 + selected_face[1] + selected_face[3],\n",
    "                                                    x1 + selected_face[0]:x1 + selected_face[0] + selected_face[2]], modelCNN, label_encoder)\n",
    "\n",
    "                    # Affichage du résultat de la prédiction\n",
    "                    label = f\"{result} ({confidence:.2%} Confiance)\" if result != \"inconnu\" else \"Inconnu\"\n",
    "\n",
    "                    # Afficher le texte \"face\" à l'intérieur de la boîte du visage\n",
    "                    cv2.putText(frame, label, (x1 + fx -40, y1 + fy - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
    "\n",
    "    # Écrire le cadre traité dans la vidéo de sortie\n",
    "    video_out.write(frame)\n",
    "    # Afficher le cadre avec les détections\n",
    "    cv2.imshow(\"Détection de personne YOLOv8\", frame)\n",
    "\n",
    "    # Quitter lorsque 'q' est pressé\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "# Libérer les ressources\n",
    "cap.release()\n",
    "video_out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
